# -*- coding: utf-8 -*-
"""android-malware-analysis-project-karthik-andrews.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bMRtdcc48JpAa3VUX6Elvv0Qa6ssZw6H
"""

from datetime import datetime

print("last update: {}".format(datetime.now()))

"""# Android Malware Analysis

### Packages
"""

from sklearn.naive_bayes import GaussianNB, BernoulliNB
from sklearn.metrics import accuracy_score, classification_report
from sklearn.ensemble import BaggingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import SGDClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import cohen_kappa_score
from sklearn.metrics import confusion_matrix
from sklearn.ensemble import RandomForestClassifier

from sklearn import preprocessing
import torch
from sklearn import svm
from sklearn import tree
import pandas as pd
import joblib
import pickle
import numpy as np
import seaborn as sns

"""### Exploratory"""

import pandas as pd
df = pd.read_csv("/kaggle/input/train1csv/train1.csv", sep=";")

print(df.head(10), sep=";")

df = df.astype("int64")
df.type.value_counts()

"""Type is the label that represents if an application is a malware or not, as we can see this dataset is balanced."""

df.shape

"""*Let's get the top 10 of permissions that are used for our malware samples*

*Malicious*
"""

pd.Series.sort_values(df[df.type==1].sum(axis=0), ascending=False)[1:11]

"""*Benign*"""

pd.Series.sort_values(df[df.type==0].sum(axis=0), ascending=False)[:10]

import matplotlib.pyplot as plt
fig, axs =  plt.subplots(nrows=2, sharex=True)

pd.Series.sort_values(df[df.type==0].sum(axis=0), ascending=False)[:10].plot.bar(ax=axs[0])
pd.Series.sort_values(df[df.type==1].sum(axis=0), ascending=False)[1:11].plot.bar(ax=axs[1], color="red")

"""The last outputs allow us to get insights about a difference between the permissions used by the malware and the benign applications.

### Modeling
"""

X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, 1:330], df['type'], test_size=0.20, random_state=42)

"""*Naive Bayes algorithm*"""

# Naive Bayes algorithm
gnb = GaussianNB()
gnb.fit(X_train, y_train)

# pred
pred = gnb.predict(X_test)

# accuracy
accuracy = accuracy_score(pred, y_test)
print("naive_bayes")
print(accuracy)
print(classification_report(pred, y_test, labels=None))

"""*kneighbors algorithm*"""

# kneighbors algorithm

for i in range(3,15,3):

    neigh = KNeighborsClassifier(n_neighbors=i)
    neigh.fit(X_train, y_train)
    pred = neigh.predict(X_test)
    # accuracy
    accuracy = accuracy_score(pred, y_test)
    print("kneighbors {}".format(i))
    print(accuracy)
    print(classification_report(pred, y_test, labels=None))
    print("")

"""*Decision Tree*"""

clf = tree.DecisionTreeClassifier()
clf.fit(X_train, y_train)

# Read the csv test file

pred = clf.predict(X_test)
# accuracy
accuracy = accuracy_score(pred, y_test)
print(clf)
print(accuracy)
print(classification_report(pred, y_test, labels=None))

"""Through the last results we can see how we trained different classifiers to detect malware using its permissions, but as I said this is only a first approximation, I didn't analyze the hyperparameters and others things to improve the results.

# Dynamic Analysis
"""

import pandas as pd
data = pd.read_csv("/kaggle/input/android-traffic1/android_traffic1.csv", sep=";")
data.head()

import pandas as pd

data = pd.read_csv("/kaggle/input/android-traffic1/android_traffic1.csv", sep=";")
data.head()

# Convert the columns to numeric
data = data.apply(pd.to_numeric, errors='coerce')

# Mask the data where anything above 300 should be greater than 300
data = data.applymap(lambda x: '>300' if x > 300 else x)

# Display the masked data
data.head()

from cryptography.fernet import Fernet
import pandas as pd

# Load the data
data = pd.read_csv("/kaggle/input/android-traffic1/android_traffic1.csv", sep=";")
data.head()

# Generate an encryption key
key = Fernet.generate_key()

# Create a Fernet object with the key
fernet = Fernet(key)

# Convert the data to a string
data_str = data.to_csv(index=False)

# Encrypt the data
encrypted_data = fernet.encrypt(data_str.encode())

# Save the encrypted data to a file
with open("encrypted_data.csv", "wb") as f:
    f.write(encrypted_data)

# Save the key to a file
with open("encryption_key.txt", "wb") as f:
    f.write(key)

# Display the encryption key
print(key)

data.columns

data.shape

data.type.value_counts()

"""In this case, we have an unbalanced dataset, so another model evaluation will be used.

### Data Cleaning and Processing
"""

data.isna().sum()

data = data.drop(['duracion','avg_local_pkt_rate','avg_remote_pkt_rate'], axis=1).copy()

data.describe()

"""Now, the idea is to see the outliers in the data"""

sns.boxplot(data.tcp_urg_packet)

data.loc[data.tcp_urg_packet > 0].shape[0]

"""That column will be no used for the analysis, only two rows are different to zero, maybe they are interesting for future analysis."""

data = data.drop(columns=["tcp_urg_packet"], axis=1).copy()
data.shape

sns.pairplot(data)

"""We have many outliers in some features, I will omit the depth analysis and only get the set of the data without the noise."""

data=data[data.tcp_packets<20000].copy()
data=data[data.dist_port_tcp<1400].copy()
data=data[data.external_ips<35].copy()
data=data[data.vulume_bytes<2000000].copy()
data=data[data.udp_packets<40].copy()
data=data[data.remote_app_packets<15000].copy()

data[data.duplicated()].sum()

data=data.drop('source_app_packets.1',axis=1).copy()

scaler = preprocessing.RobustScaler()
scaledData = scaler.fit_transform(data.iloc[:,1:11])
scaledData = pd.DataFrame(scaledData, columns=['tcp_packets','dist_port_tcp','external_ips','vulume_bytes','udp_packets','source_app_packets','remote_app_packets',' source_app_bytes','remote_app_bytes','dns_query_times'])

"""### Modeling"""

X_train, X_test, y_train, y_test = train_test_split(scaledData.iloc[:,0:10], data.type.astype("str"), test_size=0.25, random_state=45)

gnb = GaussianNB()
gnb.fit(X_train, y_train)
pred = gnb.predict(X_test)
## accuracy
accuracy = accuracy_score(y_test,pred)
print("naive_bayes")
print(accuracy)
print(classification_report(y_test,pred, labels=None))
print("cohen kappa score")
print(cohen_kappa_score(y_test, pred))

# kneighbors algorithm

for i in range(3,15,3):

    neigh = KNeighborsClassifier(n_neighbors=i)
    neigh.fit(X_train, y_train)
    pred = neigh.predict(X_test)
    # accuracy
    accuracy = accuracy_score(pred, y_test)
    print("kneighbors {}".format(i))
    print(accuracy)
    print(classification_report(pred, y_test, labels=None))
    print("cohen kappa score")
    print(cohen_kappa_score(y_test, pred))
    print("")

rdF=RandomForestClassifier(n_estimators=250, max_depth=50,random_state=45)
rdF.fit(X_train,y_train)
pred=rdF.predict(X_test)
cm=confusion_matrix(y_test, pred)

accuracy = accuracy_score(y_test,pred)
print(rdF)
print(accuracy)
print(classification_report(y_test,pred, labels=None))
print("cohen kappa score")
print(cohen_kappa_score(y_test, pred))
print(cm)